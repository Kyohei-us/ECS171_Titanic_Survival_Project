{
 "cells": [
  {
   "source": [
    "# Introduction:\n",
    "\n",
    "    We utilized LogisticRegression, both Naive Bayes, and Linear SVM models for the algorithm. \n",
    "    For testing, we used K-fold validation to test the accuracy, and grid serach when possible. \n",
    " "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# load data and imports\n",
    "import pandas as pd\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clean_titanic_df = pd.read_csv('preprocessed_titanic.csv')\n",
    "\n",
    "clean_titanic_df = clean_titanic_df.drop(columns=['Name', 'PassengerId', 'Unnamed: 0'])\n",
    "\n",
    "train, test= train_test_split(clean_titanic_df,random_state=23, test_size = 0.2)\n",
    "\n",
    "X_train, y_train = train.drop(columns=['Survived']), train['Survived']\n",
    "X_test, y_test = test.drop(columns=['Survived']), test['Survived']\n",
    "\n",
    "clean_titanic_df.head()\n",
    "clean_titanic_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 8 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Survived  891 non-null    int64  \n 1   Pclass    891 non-null    int64  \n 2   Sex       891 non-null    int64  \n 3   Age       891 non-null    float64\n 4   SibSp     891 non-null    int64  \n 5   Parch     891 non-null    int64  \n 6   Fare      891 non-null    float64\n 7   Embarked  891 non-null    int64  \ndtypes: float64(2), int64(6)\nmemory usage: 55.8 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "source": [
    "# Testing portion 1:\n",
    "* LogisticRegression \n",
    "\n",
    "* Categorical Naive Bayes : Pclass, Sex, SibSp, Parch, and Embarked are turned into one-hot-encoded attributes. Age and Fare are label encoded(0~n-1)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_log = clean_titanic_df.drop(columns=['Survived'])\n",
    "y_log = clean_titanic_df['Survived']\n",
    "\n",
    "X_log_num = X_log[['Age', 'Fare']]\n",
    "\n",
    "X_log_cat_encoded_Pclass = pd.get_dummies(X_log['Pclass'], prefix='Pclass')\n",
    "print(X_log_cat_encoded_Pclass)\n",
    "X_log_cat_encoded_Sex = pd.get_dummies(X_log['Sex'], prefix='Sex')\n",
    "X_log_cat_encoded_SibSp = pd.get_dummies(X_log['SibSp'], prefix='SibSp')\n",
    "X_log_cat_encoded_Parch = pd.get_dummies(X_log['Parch'], prefix='Parch')\n",
    "X_log_cat_encoded_Embarked = pd.get_dummies(X_log['Embarked'], prefix='Embarked')\n",
    "X_log_cat_encoded = pd.concat([X_log_cat_encoded_Pclass, X_log_cat_encoded_Sex, X_log_cat_encoded_SibSp, X_log_cat_encoded_Parch, X_log_cat_encoded_Embarked], axis=1)\n",
    "\n",
    "X_log =  X_log_cat_encoded.join(X_log_num)\n",
    "\n",
    "X_train_log, X_test_log= train_test_split(X_log,random_state=23, test_size = 0.2)\n",
    "\n",
    "# print(X_train_log)\n",
    "\n",
    "lor = LogisticRegression(penalty= 'none', max_iter= 1000, solver='newton-cg').fit(X_train_log, y_train)\n",
    "print(classification_report(y_test, lor.predict(X_test_log)))\n",
    "print(lor.score(X_test_log, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Pclass_1  Pclass_2  Pclass_3\n0           0         0         1\n1           1         0         0\n2           0         0         1\n3           1         0         0\n4           0         0         1\n..        ...       ...       ...\n886         0         1         0\n887         1         0         0\n888         0         0         1\n889         1         0         0\n890         0         0         1\n\n[891 rows x 3 columns]\n              precision    recall  f1-score   support\n\n           0       0.81      0.83      0.82       115\n           1       0.69      0.66      0.67        64\n\n    accuracy                           0.77       179\n   macro avg       0.75      0.75      0.75       179\nweighted avg       0.77      0.77      0.77       179\n\n0.770949720670391\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Apply 10-fold cross validation on logistic regression\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "\r\n",
    "i = 0\r\n",
    "average_score = 0\r\n",
    "for train_indices, test_indices in kf.split(X_log):\r\n",
    "    #print(train_indices)\r\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\r\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\r\n",
    "    \r\n",
    "    lor = LogisticRegression(penalty= 'none', max_iter= 1000, solver='newton-cg').fit(X_log[start_train:stop_train], y_log[start_train:stop_train])\r\n",
    "    print( classification_report( y_log[start_test:stop_test], lor.predict( X_log[start_test:stop_test] ) ) )\r\n",
    "    print(lor.score( X_log[start_test:stop_test], y_log[start_test:stop_test] ))\r\n",
    "    average_score += lor.score( X_log[start_test:stop_test], y_log[start_test:stop_test] )\r\n",
    "    i+=1\r\n",
    "\r\n",
    "print(\"average score: \", average_score/10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        51\n",
      "           1       0.77      0.69      0.73        39\n",
      "\n",
      "    accuracy                           0.78        90\n",
      "   macro avg       0.78      0.77      0.77        90\n",
      "weighted avg       0.78      0.78      0.78        90\n",
      "\n",
      "0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89        69\n",
      "           1       0.60      0.75      0.67        20\n",
      "\n",
      "    accuracy                           0.83        89\n",
      "   macro avg       0.76      0.80      0.78        89\n",
      "weighted avg       0.85      0.83      0.84        89\n",
      "\n",
      "0.8314606741573034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83        55\n",
      "           1       0.76      0.65      0.70        34\n",
      "\n",
      "    accuracy                           0.79        89\n",
      "   macro avg       0.78      0.76      0.77        89\n",
      "weighted avg       0.78      0.79      0.78        89\n",
      "\n",
      "0.7865168539325843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84        44\n",
      "           1       0.86      0.82      0.84        45\n",
      "\n",
      "    accuracy                           0.84        89\n",
      "   macro avg       0.84      0.84      0.84        89\n",
      "weighted avg       0.84      0.84      0.84        89\n",
      "\n",
      "0.8426966292134831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82        52\n",
      "           1       0.73      0.81      0.77        37\n",
      "\n",
      "    accuracy                           0.80        89\n",
      "   macro avg       0.79      0.80      0.79        89\n",
      "weighted avg       0.80      0.80      0.80        89\n",
      "\n",
      "0.797752808988764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        57\n",
      "           1       0.72      0.66      0.69        32\n",
      "\n",
      "    accuracy                           0.79        89\n",
      "   macro avg       0.77      0.76      0.76        89\n",
      "weighted avg       0.78      0.79      0.78        89\n",
      "\n",
      "0.7865168539325843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        50\n",
      "           1       0.83      0.64      0.72        39\n",
      "\n",
      "    accuracy                           0.79        89\n",
      "   macro avg       0.80      0.77      0.78        89\n",
      "weighted avg       0.79      0.79      0.78        89\n",
      "\n",
      "0.7865168539325843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85        56\n",
      "           1       0.83      0.58      0.68        33\n",
      "\n",
      "    accuracy                           0.80        89\n",
      "   macro avg       0.81      0.75      0.77        89\n",
      "weighted avg       0.80      0.80      0.79        89\n",
      "\n",
      "0.797752808988764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        59\n",
      "           1       0.74      0.77      0.75        30\n",
      "\n",
      "    accuracy                           0.83        89\n",
      "   macro avg       0.81      0.82      0.81        89\n",
      "weighted avg       0.83      0.83      0.83        89\n",
      "\n",
      "0.8314606741573034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88        56\n",
      "           1       0.81      0.76      0.78        33\n",
      "\n",
      "    accuracy                           0.84        89\n",
      "   macro avg       0.83      0.83      0.83        89\n",
      "weighted avg       0.84      0.84      0.84        89\n",
      "\n",
      "0.8426966292134831\n",
      "average score:  0.8081148564294631\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# try to find optimal max iteration \r\n",
    "\r\n",
    "max_iterations = [x*100 for x in range(1,10)]\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "for i in max_iterations:\r\n",
    "    lor = LogisticRegression(penalty= 'none', max_iter= i, solver='newton-cg').fit(X_train_log, y_train)\r\n",
    "    print(classification_report(y_test, lor.predict(X_test_log)))\r\n",
    "    print(\"Score for max iteration of {}\".format(i))\r\n",
    "    print(lor.score(X_test_log, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 100\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 200\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 300\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 400\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 500\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 600\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 700\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 800\n",
      "0.770949720670391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       115\n",
      "           1       0.69      0.66      0.67        64\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.75      0.75      0.75       179\n",
      "weighted avg       0.77      0.77      0.77       179\n",
      "\n",
      "Score for max iteration of 900\n",
      "0.770949720670391\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "source": [
    "## End of Logistic Regression portion"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# create age categories (DO NO RUN THIS CELL TWICE! IF RAN A SECOND TIME, MOST VALUES WILL BE TURNED INTO 1):\n",
    "age_bins = pd.cut( clean_titanic_df['Age'], 10, retbins = True)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "while i < 72:\n",
    "    clean_titanic_df.loc[(clean_titanic_df['Age'] > i) &  (clean_titanic_df['Age'] <= i +8), 'Age'] = j\n",
    "    j += 1\n",
    "    i += 8\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create Fare category\r\n",
    "\r\n",
    "fare_bins = pd.qcut(clean_titanic_df['Fare'], 5, retbins = True)\r\n",
    "print(fare_bins)\r\n",
    "\r\n",
    "clean_titanic_df.loc[clean_titanic_df['Fare'] <= 7, 'Fare'] = 0\r\n",
    "clean_titanic_df.loc[(clean_titanic_df['Fare'] > 7) & (clean_titanic_df['Fare'] <= 10 ), 'Fare'] = 1\r\n",
    "clean_titanic_df.loc[(clean_titanic_df['Fare'] > 10) & (clean_titanic_df['Fare'] <= 21 ), 'Fare'] = 2\r\n",
    "clean_titanic_df.loc[(clean_titanic_df['Fare'] > 21) & (clean_titanic_df['Fare'] <= 40 ), 'Fare'] = 3\r\n",
    "clean_titanic_df.loc[clean_titanic_df['Fare'] > 40 , 'Fare'] = 4"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "source": [
    "train, test= train_test_split(clean_titanic_df,random_state=23, test_size = 0.2)\r\n",
    "\r\n",
    "X_train, y_train = train.drop(columns=['Survived']), train['Survived']\r\n",
    "X_test, y_test = test.drop(columns=['Survived']), test['Survived']"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Categorical Bayes classifier\r\n",
    "\r\n",
    "from sklearn.naive_bayes import CategoricalNB\r\n",
    "\r\n",
    "categorical_NB2 = CategoricalNB()\r\n",
    "categorical_NB2.fit(X_train, y_train)\r\n",
    "print(classification_report(y_test, categorical_NB2.predict(X_test)))\r\n",
    "print(categorical_NB2.score(X_test, y_test))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       115\n",
      "           1       0.75      0.62      0.68        64\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.78      0.76      0.77       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "0.7932960893854749\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Apply 10-fold cross validation on Categorical Naive Bayes Classifier\r\n",
    "\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from sklearn.naive_bayes import CategoricalNB\r\n",
    "kf = KFold(n_splits=10)\r\n",
    "\r\n",
    "X = clean_titanic_df.drop(columns=['Survived'])\r\n",
    "y = clean_titanic_df['Survived']\r\n",
    "\r\n",
    "i = 0\r\n",
    "average_score = 0\r\n",
    "for train_indices, test_indices in kf.split(X):\r\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\r\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\r\n",
    "\r\n",
    "\r\n",
    "    categorical_NB2 = CategoricalNB()\r\n",
    "    categorical_NB2.fit(X[start_train:stop_train], y[start_train:stop_train])\r\n",
    "    print(classification_report(y[start_test:stop_test], categorical_NB2.predict(X[start_test:stop_test])))\r\n",
    "    print(categorical_NB2.score(X[start_test:stop_test], y[start_test:stop_test]))\r\n",
    "    average_score += categorical_NB2.score(X[start_test:stop_test], y[start_test:stop_test])\r\n",
    "    i+=1\r\n",
    "\r\n",
    "print(\"average score: \", average_score/10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.82      0.72        51\n",
      "           1       0.64      0.41      0.50        39\n",
      "\n",
      "    accuracy                           0.64        90\n",
      "   macro avg       0.64      0.62      0.61        90\n",
      "weighted avg       0.64      0.64      0.63        90\n",
      "\n",
      "0.6444444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88        69\n",
      "           1       0.57      0.60      0.59        20\n",
      "\n",
      "    accuracy                           0.81        89\n",
      "   macro avg       0.73      0.73      0.73        89\n",
      "weighted avg       0.81      0.81      0.81        89\n",
      "\n",
      "0.8089887640449438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85        55\n",
      "           1       0.81      0.65      0.72        34\n",
      "\n",
      "    accuracy                           0.81        89\n",
      "   macro avg       0.81      0.78      0.79        89\n",
      "weighted avg       0.81      0.81      0.80        89\n",
      "\n",
      "0.8089887640449438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        44\n",
      "           1       0.87      0.76      0.81        45\n",
      "\n",
      "    accuracy                           0.82        89\n",
      "   macro avg       0.83      0.82      0.82        89\n",
      "weighted avg       0.83      0.82      0.82        89\n",
      "\n",
      "0.8202247191011236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        52\n",
      "           1       0.81      0.70      0.75        37\n",
      "\n",
      "    accuracy                           0.81        89\n",
      "   macro avg       0.81      0.79      0.80        89\n",
      "weighted avg       0.81      0.81      0.81        89\n",
      "\n",
      "0.8089887640449438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        57\n",
      "           1       0.89      0.78      0.83        32\n",
      "\n",
      "    accuracy                           0.89        89\n",
      "   macro avg       0.89      0.86      0.87        89\n",
      "weighted avg       0.89      0.89      0.89        89\n",
      "\n",
      "0.8876404494382022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88        50\n",
      "           1       0.91      0.74      0.82        39\n",
      "\n",
      "    accuracy                           0.85        89\n",
      "   macro avg       0.87      0.84      0.85        89\n",
      "weighted avg       0.86      0.85      0.85        89\n",
      "\n",
      "0.8539325842696629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84        56\n",
      "           1       0.74      0.70      0.72        33\n",
      "\n",
      "    accuracy                           0.80        89\n",
      "   macro avg       0.78      0.78      0.78        89\n",
      "weighted avg       0.80      0.80      0.80        89\n",
      "\n",
      "0.797752808988764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        59\n",
      "           1       0.78      0.70      0.74        30\n",
      "\n",
      "    accuracy                           0.83        89\n",
      "   macro avg       0.82      0.80      0.81        89\n",
      "weighted avg       0.83      0.83      0.83        89\n",
      "\n",
      "0.8314606741573034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89        56\n",
      "           1       0.83      0.76      0.79        33\n",
      "\n",
      "    accuracy                           0.85        89\n",
      "   macro avg       0.85      0.83      0.84        89\n",
      "weighted avg       0.85      0.85      0.85        89\n",
      "\n",
      "0.8539325842696629\n",
      "average score:  0.8116354556803994\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "source": [
    "## End of Categorical Naive Bayes Classifier portioin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing portion 2: \n",
    "* Gaussian Naive Bayes : Age, Number of sibling, Number of parents, and Fare are used as  numerical attributes\n",
    "\n",
    "* Linear SVM : Same as Gaussian but joined by One-hot-encoded class, survived, and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           Age  SibSp  Parch     Fare\n0    22.000000      1      0   7.2500\n1    38.000000      1      0  71.2833\n2    26.000000      0      0   7.9250\n3    35.000000      1      0  53.1000\n4    35.000000      0      0   8.0500\n..         ...    ...    ...      ...\n886  27.000000      0      0  13.0000\n887  19.000000      0      0  30.0000\n888  29.699118      1      2  23.4500\n889  26.000000      0      0  30.0000\n890  32.000000      0      0   7.7500\n\n[891 rows x 4 columns]\n     Survived\n0           0\n1           1\n2           1\n3           1\n4           0\n..        ...\n886         0\n887         1\n888         0\n889         1\n890         0\n\n[891 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "clean_titanic_df = pd.read_csv('preprocessed_titanic.csv')\n",
    "\n",
    "clean_titanic_df = clean_titanic_df.drop(columns=['Name', 'PassengerId', 'Unnamed: 0'])\n",
    "\n",
    "\n",
    "X_Numerical = clean_titanic_df[[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]]\n",
    "print(X_Numerical)\n",
    "y_Numerical = clean_titanic_df[[\"Survived\"]]\n",
    "print(y_Numerical)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X_Numerical,y_Numerical , test_size = 0.20, random_state = 23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.72      0.97      0.83       115\n           1       0.87      0.31      0.46        64\n\n    accuracy                           0.74       179\n   macro avg       0.79      0.64      0.64       179\nweighted avg       0.77      0.74      0.70       179\n\n0.7374301675977654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "Gaussian_NB = GaussianNB()\n",
    "Gaussian_NB.fit(X_train, y_train.values.ravel())\n",
    "print(classification_report(y_test, Gaussian_NB.predict(X_test)))\n",
    "print(Gaussian_NB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.59      0.90      0.71        51\n           1       0.58      0.18      0.27        39\n\n    accuracy                           0.59        90\n   macro avg       0.59      0.54      0.49        90\nweighted avg       0.59      0.59      0.52        90\n\n0.5888888888888889\n              precision    recall  f1-score   support\n\n           0       0.78      0.93      0.85        69\n           1       0.29      0.10      0.15        20\n\n    accuracy                           0.74        89\n   macro avg       0.53      0.51      0.50        89\nweighted avg       0.67      0.74      0.69        89\n\n0.7415730337078652\n              precision    recall  f1-score   support\n\n           0       0.68      0.98      0.80        55\n           1       0.89      0.24      0.37        34\n\n    accuracy                           0.70        89\n   macro avg       0.78      0.61      0.59        89\nweighted avg       0.76      0.70      0.64        89\n\n0.6966292134831461\n              precision    recall  f1-score   support\n\n           0       0.61      0.95      0.74        44\n           1       0.90      0.40      0.55        45\n\n    accuracy                           0.67        89\n   macro avg       0.75      0.68      0.65        89\nweighted avg       0.76      0.67      0.65        89\n\n0.6741573033707865\n              precision    recall  f1-score   support\n\n           0       0.63      0.92      0.75        52\n           1       0.69      0.24      0.36        37\n\n    accuracy                           0.64        89\n   macro avg       0.66      0.58      0.55        89\nweighted avg       0.66      0.64      0.59        89\n\n0.6404494382022472\n              precision    recall  f1-score   support\n\n           0       0.67      0.93      0.78        57\n           1       0.60      0.19      0.29        32\n\n    accuracy                           0.66        89\n   macro avg       0.64      0.56      0.53        89\nweighted avg       0.65      0.66      0.60        89\n\n0.6629213483146067\n              precision    recall  f1-score   support\n\n           0       0.62      0.96      0.76        50\n           1       0.83      0.26      0.39        39\n\n    accuracy                           0.65        89\n   macro avg       0.73      0.61      0.57        89\nweighted avg       0.72      0.65      0.60        89\n\n0.651685393258427\n              precision    recall  f1-score   support\n\n           0       0.70      0.96      0.81        56\n           1       0.83      0.30      0.44        33\n\n    accuracy                           0.72        89\n   macro avg       0.77      0.63      0.63        89\nweighted avg       0.75      0.72      0.68        89\n\n0.7191011235955056\n              precision    recall  f1-score   support\n\n           0       0.73      0.95      0.82        59\n           1       0.75      0.30      0.43        30\n\n    accuracy                           0.73        89\n   macro avg       0.74      0.62      0.63        89\nweighted avg       0.73      0.73      0.69        89\n\n0.7303370786516854\n              precision    recall  f1-score   support\n\n           0       0.69      1.00      0.82        56\n           1       1.00      0.24      0.39        33\n\n    accuracy                           0.72        89\n   macro avg       0.85      0.62      0.60        89\nweighted avg       0.81      0.72      0.66        89\n\n0.7191011235955056\naverage score:  0.6824843945068665\n"
     ]
    }
   ],
   "source": [
    "# using k-fold (10 fold) cross validation\n",
    "#from sklearn.model_selection import cross_validate\n",
    "#scores = cross_validate(Gaussian_NB, X_Numerical,y_Numerical.values.ravel(),cv = 10, scoring= ('neg_mean_squared_error' , 'accuracy', 'recall_macro','recall_weighted','f1_macro','f1_weighted') )\n",
    "#score_total = 0\n",
    "#MSE_total = 0\n",
    "#for label in scores:\n",
    "   # print(label)\n",
    "#for idx, s in enumerate{scores[\"test_accuracy\"]):\n",
    "#    print(s)\n",
    "#    score_total += s\n",
    "n = 10\n",
    "kf = KFold(n_splits=n)\n",
    "\n",
    "X = X_Numerical\n",
    "y = y_Numerical.values.ravel()\n",
    "\n",
    "i = 0\n",
    "average_score = 0\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "\n",
    "\n",
    "    Gaussian_NB = GaussianNB()\n",
    "    Gaussian_NB.fit(X[start_train:stop_train], y[start_train:stop_train])\n",
    "    print(classification_report(y[start_test:stop_test], Gaussian_NB.predict(X[start_test:stop_test])))\n",
    "    print(Gaussian_NB.score(X[start_test:stop_test], y[start_test:stop_test]))\n",
    "    average_score += Gaussian_NB.score(X[start_test:stop_test], y[start_test:stop_test])\n",
    "    i+=1\n",
    "\n",
    "print(\"average score: \", average_score/n)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## End of Gaussian Naive Bayes Section"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## End of SVM Section"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('3.8')"
  },
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}